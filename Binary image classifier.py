# -*- coding: utf-8 -*-
"""Tune_Soccer_Rugby.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e_BeX25Z2DJF0pXXBcgefnoY0VAOjJ3v
"""

import matplotlib.pyplot as plt
import seaborn as sns
import gc
import numpy as np
from tensorflow.keras import backend as K 
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout 
from keras.preprocessing.image import ImageDataGenerator
#from keras.optimizers import Adam
#from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import Adadelta
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import roc_auc_score
import tensorflow as tf
from sklearn.metrics import PrecisionRecallDisplay

import cv2
import os

import numpy as np
#!pip install timm

from google.colab import drive
drive.mount('/content/drive/')

labels = ['rugby', 'soccer']
img_size = 224
def get_data(data_dir):
    data = [] 
    for label in labels: 
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format
                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)
    return np.array(data)

train = get_data('/content/drive/MyDrive/RugbySoccer/train')
val = get_data('/content/drive/MyDrive/RugbySoccer/tuneval')
test= get_data('/content/drive/MyDrive/RugbySoccer/tunetest')

def clean_up(model):
    K.clear_session()
    del model
    gc.collect()

"""Data preprocessing


"""

x_train = []
y_train = []
x_val = []
y_val = []
x_test = []
y_test = []

for feature, label in train:
  x_train.append(feature)
  y_train.append(label)

for feature, label in val:
  x_val.append(feature)
  y_val.append(label)

for feature, label in test:
  x_test.append(feature)
  y_test.append(label)
# Normalize the data of all sets
x_train = np.array(x_train) / 255
x_val = np.array(x_val) / 255
x_test = np.array(x_test) / 255

x_train.reshape(-1, img_size, img_size, 1)
y_train = np.array(y_train)

x_val.reshape(-1, img_size, img_size, 1)
y_val = np.array(y_val)

x_test.reshape(-1, img_size, img_size, 1)
y_test = np.array(y_val)

#Defining hyperparameter space --Grid Search, random could be used also
activation_functions_inner=["relu","sigmoid","softmax"]
activation_functions_output=["relu","sigmoid","softmax"]
dropout=[0.2,0.4,0.6]
density=[64,96,128]
learn_rate=[0.00001,0.000005,0.000001]
#keeping combination of hyperparameters that provide max accuracy
max_accuracy=0
max_a=0
max_b=0
max_c=0
max_d=0
max_e=0        
training_epochs=5

#Hyperparameter tuning start
for a in range(len(activation_functions_inner)):
  for b in range(len(activation_functions_output)):
    for c in range(len(dropout)):
      for d in range(len(density)):
        for e in range(len(learn_rate)):
          model = Sequential()
          model.add(Conv2D(32,3,padding="same", activation=activation_functions_inner[a], input_shape=(224,224,3)))
          model.add(MaxPool2D())

          model.add(Conv2D(32, 3, padding="same", activation=activation_functions_inner[a]))
          model.add(MaxPool2D())
          model.add(Dropout(dropout[c]))

          model.add(Conv2D(64, 3, padding="same", activation=activation_functions_inner[a]))
          model.add(MaxPool2D())
          model.add(Dropout(dropout[c]))

          model.add(Flatten())
          model.add(Dense(density[d],activation=activation_functions_inner[a]))
          model.add(Dense(2, activation=activation_functions_output[b]))
          model.add(Dropout(dropout[c]))

          model.summary()
          opt = Adam(learning_rate=learn_rate[e])
          model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])
          history = model.fit(x_train,y_train,epochs = training_epochs , validation_data = (x_val, y_val))
          acc = history.history['accuracy']
          if (max(acc)>max_accuracy):
            max_accuracy=max(acc)
            max_a=a
            max_b=b
            max_c=c
            max_d=d
            max_e=e

#Since best hyperparameter combination set is found, move on and train with  more epochs and prediction with testing set
model = Sequential()
model.add(Conv2D(32,3,padding="same", activation=activation_functions_inner[max_a], input_shape=(224,224,3)))
model.add(MaxPool2D())

model.add(Conv2D(32, 3, padding="same", activation=activation_functions_inner[max_a]))
model.add(MaxPool2D())
model.add(Dropout(dropout[max_c]))

model.add(Conv2D(64, 3, padding="same", activation=activation_functions_inner[max_a]))
model.add(MaxPool2D())
model.add(Dropout(dropout[max_c]))

model.add(Flatten())
model.add(Dense(max_d,activation=activation_functions_inner[max_a]))
model.add(Dense(2, activation=activation_functions_output[max_b]))
model.add(Dropout(dropout[max_c]))

model.summary()
opt = Adam(learning_rate=learn_rate[max_e])
model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])
history = model.fit(x_train,y_train,epochs = 25 , validation_data = (x_val, y_val))

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(25)

plt.figure(figsize=(15, 15))
plt.subplot(2, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
#recall and precision and f1 as metrics
#auc

predict_x=model.predict(x_test) 
classes_x=np.argmax(predict_x,axis=1)

print(classification_report(y_test, classes_x, target_names = ['Rugby (Class 0)','Soccer (Class 1)']))

roc_auc_score(y_test, classes_x)

display = PrecisionRecallDisplay.from_predictions(
     y_test,classes_x, name="CNN 3 Layered"
)

